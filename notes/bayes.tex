
\section{Probability and Bayesian inference}
\only<article>{One of the most important methods in machine learning
  and statistics is that of Bayesian inference.  This is the most
  fundamental method of drawing conclusions from data and explicit
  prior assumptions. In Bayesian inference, prior assumptions are
  represented as a probabilities on a space of hypothesis. Each
  hypothesis is seen as a probabilistic model of all possible data
  that we can see.}

\only<article>{Frequently, we want to draw conclusions from data. However, the conclusions are never solely inferred from data, but also depend on prior assumptions about reality. 


  \begin{example}
    John claims he has psychic powers and can predict a series of coin tosses. We oblige, and throw a coin 8 times.  John predicts 8 out of 8 coin tosses. The probability of him doing so by chance is $2^{-8}$. If he was a medium, as he claims, then his probability of achieving the feat would be $1$. Should we believe John?
  \end{example}


  \begin{example}
    Traces of DNA are found at a murder scene. We perform a DNA test against a database of $10^4$ citizens registered to be living in the area. We know that the probability of a false positive (that is, the test finding a match by mistake) is $10^{-6}$. If there is a match in the database, does that mean that the citizen was at the scene of the crime?
  \end{example}

  Answering these questions requires us to clearly define what are the possible hypotheses we wish to consider. Taking the first example, we can define two:
  \begin{enumerate}
  \item hypothesis $\model_1$, that John is a medium.
  \item hypothesis $\model_0$, that John is not a medium.
  \end{enumerate}
  We can also define a probability model for the number of successful predictions that John would make in either case. 

  Let $x_t$ be $0$ if John makes an incorrect prediction at time $t$ and $x_t = 1$ if he makes a correct prediction. John's claim that he can predict our tosses perfectly means that for a sequence of tosses $\bx = x_1, \ldots, x_n$,
  \[
    \Pr(\bx \mid \model_1) = \begin{cases}
      1, & x_t = 1 \forall t \in [n]\\
      0, & \exists t \in [n] : x_t = 0.
    \end{cases}
  \]
  That is, the probability of perfectly correct predictions is 1, and that of one or more incorrect prediction is 0. For the other model, we can assume that all draws are independently and identically distributed from a fair coin. Consequently, no matter what John's predictions are, we have that:
  \[
    \Pr(\bx \mid \model_0) = 2^{-n}.
  \]
  So, for the given example, as stated, we have the following facts:
  \begin{itemize}
  \item If John makes one or more mistakes, then $\Pr(\bx \mid \model_1) = 0$ and $\Pr(\bx \mid \model_0) = 2^{-n}$. Thus, we should perhaps say that then John is not a medium
  \item If John makes no mistakes at all, then 
    \begin{align}
      \Pr(\bx \mid \model_1) &= 1,
      &
        \Pr(\bx \mid \model_0) &= 2^{-n}.
    \end{align}
  \end{itemize}
  Does that mean that we must conclude that John is a medium? What if
  $n = 1$? What if $n=100$?  In fact, our conclusion should somehow
  depend on the strength of the evidence. Should it also not depend on how
  likely we think that a medium exists?

  It is this latter idea that we'll try and exploit. We'd like to combine the weight of the evidence, with the weight of our prior beliefs about reality.
  To do this, we first recall the definition of conditional probability. 
}


\subsection{Conditional probability and Bayesian inference}
\begin{frame}
  \frametitle{A medium}
  \begin{example}
    John claims to be a medium. He throws a coin $n$ times and predicts its value always correctly. Should we believe that he is a medium?
  \end{example}
  \begin{itemize}
  \item $\model_1$: John is a medium.
  \item $\model_0$: John is not a medium.
  \end{itemize}
  The answer depends on what we \alert{expect} a medium to be able to do, and how likely we thought he'd be a medium in the first place.
\end{frame}
\only<article>{
  Let $A$ and $B$ be two events. Let $P(A)$ be the probability of event $A$ and $P(B)$ the probability of event $B$. We can think of the probability of an event as the \emph{relative size} of the event in the space of probabilities.\footnote{More formally, probability is a measure; a function similar to volume, area, length and mass.} 
  The probability of both events $A$ and $B$ happening at the same time is denoted by $P(A \cap B)$.  This amounts to measuring the size of the space by the intersection of $A$ and $B$.
  The basic probability laws are the following.
}
\begin{frame}
  \begin{block}{Axioms of probability}
    \begin{enumerate}
    \item The probability of the certain event is $P(\Omega) = 1$
    \item The probability of the impossible event is
      $P(\emptyset) = 0$
    \item The probability of any event $A$ is $1 \leq P(A) \geq 0$.
    \item If $A, B$ are disjoint, i.e. $A \cap B = \emptyset$, meaning
      that they cannot happen at the same time, then
      \[
        P(A \cup B) = P(A) + P(B)
      \]
    \end{enumerate}
  \end{block}
\end{frame}

\begin{frame}
  \only<article>{ Sometimes we would like to calculate the probability
    of some event $A$ happening given that we know that some other
    event $B$ has happened. For this we need to first define the idea
    of conditional probability.  }
  \begin{definition}[Conditional probability]
    The probability of $A$ happening if we know that $B$ has happened
    is defined to be:
    \[
      P(A \mid B) \defn \frac{P(A \cap B) }{P(B)}.
    \]
  \end{definition}
  \only<article>{
    Here, the probability measure of any event $A$ given $B$ is defined to be the probability of the intersection of of the events divided by the second event.
    We can rewrite this definition as follows, by using the definition for $P(B \mid A)$}
  \begin{block}{Bayes's theorem}
    \[
      P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}.
    \]
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Bayesian inference}
  \only<article>{
    Now let us apply this idea to our specific problem. We already have the probability of the observation for each model, but we just need to define a \emph{prior probability} for each model. Since this is usually completely subjective, we give it another symbol.
  }
  \begin{block}{Prior probability}
    The prior probability $\bel$ on a set of models $\Model$ specifies our subjective belief $\bel(\model)$ that each model is true.\footnote{More generally $\bel$ is a probability measure.}
  \end{block}
  \only<article>{
    This allows us to calculate the probability of John being a medium, given the data:
    \[
      \bel(\model_1 \mid \bx) = \frac{\Pr(\bx \mid \model_1) \bel(\model_1)}{\Pr_\bel(\bx)},
    \]
    where
    \[
      \Pr_\bel(\bx) \defn \Pr(\bx \mid \model_1) \bel(\model_1) + \Pr(\bx \mid \model_0) \bel(\model_0).
    \]
    The only thing left to specify is $\bel(\model_1)$, the probability that John is a medium before seeing the data. This is our subjective prior belief that mediums exist and that John is one of them.
    More generally, we can think of Bayesian inference as follows: }
  \begin{itemize}
  \item We start with a set of mutually exclusive hypotheses $\Model = \{\model_1, \ldots, \model_k\}$.
  \item Each hypothesis $\model$ is represented by a specific probabilistic model for any possible data $\bx$, that is $\Pr(\bx \mid \model)$.
  \item For each hypothesis, we have a prior probability $\bel(\model)$ that it is correct.
  \item After observing the data, we can calculate a posterior probability that the hypothesis is correct:
    \[
      \bel(\model \mid \bx) = \frac{\Pr(\bx \mid \model) \bel(\model)}{\sum_{i=1}^k \Pr(\bx \mid \model_i) \bel(\model_i)}.
    \]
  \end{itemize}
  Combining the prior belief with evidence is key in this procedure. Our posterior belief can then be used as a new prior belief when we get more evidence.
\end{frame}






\begin{frame}
  \begin{block}{Bayes's theorem}
    \[
      P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}.
    \]
  \end{block}
  \only<article>{ Now let us apply this idea to our specific
    problem. This allows us to calculate the probability of John being
    a medium, given the data:
    \[
      \Pr(\model_1 \mid \bx) = \frac{\Pr(\bx \mid \model_1)
        \Pr(\model_1)}{\Pr(\bx)},
    \]
    where
    \[
      \Pr(\bx) = \Pr(\bx \mid \model_1) \Pr(\model_1) + \Pr(\bx \mid
      \model_0) \Pr(\model_0).
    \]
    The only thing left to specify is $\Pr(\model_1)$, the probability
    that John is a medium before seeing the data. This is our
    subjective prior belief that mediums exist and that John is one of
    them.

    More generally, we can think of Bayesian inference as follows:
    \begin{itemize}
    \item We start with a set of mutually exclusive hypotheses
      $H = \{\model_1, \ldots, \model_k\}$.
    \item Each hypothesis $\model$ is represented by a specific
      probabilistic model for any possible data $\bx$, that is
      $\Pr(\bx \mid \model)$.
    \item For each hypothesis, we have a prior probability
      $\Pr(\model)$ that it is correct.
    \item After observing the data, we can calculate a posterior
      probability that the hypothesis is correct:
      \[
        \Pr(\model \mid \bx) = \frac{\Pr(\bx \mid \model)
          \Pr(\model)}{\sum_{i=1}^k \Pr(\bx \mid \model_i)
          \Pr(\model_i)}.
      \]
    \end{itemize}
    Combining the prior belief with evidence is key in this
    procedure. Our posterior belief can then be used as a new prior
    belief when we get more evidence.  }
\end{frame}


\subsection{Classification and conditional probability estimation}
\only<article>{
  Conditional probability naturally appears in classification problems. Given a new example vector of data $\bx \in \Reals^n$, we would like to calculate the probability of different classes $c \in \CY$ given the data, $\Pr(y_t = c \mid \bx)$.   From Bayes's theorem, we see that we can write this as
}
\[
  \Pr(y_t = c \mid \bx) = \frac{\Pr(\bx \mid y_t = c) \Pr(y_t = c)}{\sum_{c' \in \CY} \Pr(\bx \mid y_t = c') \Pr(y_t = c')}
\]
\only<article>{
  for any class $C$. This directly gives us a method for classifying new data, as long as we have a way to obtain $\Pr(\bx \mid C)$ and $\Pr(C)$.
}




\subsection{Full Bayesian inference}
\only<article>{Statistical inference is the problem estimating quantities from data. Many machine learning problems lie within the statistical inference framework. While there are many paradigms within this framework, one typically tries to calculate probability distributions of some random variables from data. These are usually expressed in terms of parametrised distributions. In the Bayesian setting in particular, the goal is to quantify our uncertainty about these unknown parameters in terms of another probability distribution.}
\begin{frame}
  \frametitle{Bayesian inference} \only<article>{ Bayesian statistical
    inference is the problem of inferring distributions (of
    parameters) from data. Typically, given some prior distribution
    $\bel(\model)$ on parameters $\model \in \Model$, such that for
    every possible parameter value the probability $P_\model(x)$ is
    well defined for any $x \in \CX$, we wish to infer a posterior
    distribution from any given data $x$.}
  \begin{definition}[Posterior distribution]
    \only<article>{Given a prior $\bel$ on the parameter set $\Model$
      and a family $\{P_\model\}$ of distributions on $\CX$, the
      posterior distribution of parameter $\model$ for any data
      $x \in \CX$ is}
    \begin{equation}
      \bel(\model \mid x) \defn \frac{P_\model(x) \bel(\model)}{\sum_{\model' \in \Model}
        P_{\model'}(x) \bel(\model')}.
      \label{eq:posterior}
    \end{equation}
  \end{definition}
\end{frame}






%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "notes.tex"
%%% End:
