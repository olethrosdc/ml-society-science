\documentclass[a4paper,twoside]{book}

\usepackage[notheorems]{beamerarticle}



\mode<presentation>{
  % \useinnertheme{rectangles}
  %\useoutertheme{infolines}
  % \usecolortheme{crane}
  % \usecolortheme{rose}
}
\input{../preamble}

%\includeonly{database,privacy}
\includeonly{experiment-design}
\title{Machine learning in science and society}
\subtitle{From automated science to beneficial artificial intelligence}
\author[C. Dimitrakakis]{Christos Dimitrakakis}
\begin{document}

\maketitle
\tableofcontents

\chapter{Introduction}
\include{ml-intro}

\chapter{Simple decision problems}

\only<article>{This chapter deals with simple decision problems, whereby a decision maker (DM) makes a simple choice among many. In some of this problems the DM has to make a decision after first observing some side-information. Then the DM uses a \emph{decision rule} to assign a probability to each possible decision for each possible side-information. However, designing the decision rule is not trivial , as it relies on previously collected data. A higher-level decision includes choosing the decision rule itself. The problems of classification and regression fall within this framework. While most steps in the process can be automated and formalised, a lot of decisions are actual design choices made by humans. This creates scope for errors and misinterpretation of results.

In this chapter, we shall formalise all these simple decision problems from the point of view of statistical decision theory. The first question is, given a real world application, what type of decision problem does it map to? Then, what kind of machine learning algorithms can we use to solve it? What are the underlying assumptions and how valid are our conclusions? 
}

\include{knn}  % knn, reproducability and bootstrapping
\include{bayes} % Bayesian inference
\include{decision-problems} % decision hierarchies

\include{ann} % linear models and stochastic gradient descent
\include{naive-bayes} %
\include{p-values}

\include{reproducibility}

\chapter{Privacy}
\only<article>{
  Participating in a study always carries a risk for individuals, namely that of data disclosure.
}

\include{database} % data base access model
\include{privacy} %data bases

\chapter{Fairness}

\include{fairness}
\include{credit}

\chapter{Structured and large databases}
\only<article>{Structured learning problems involve multiple latent variables with a complex structure. These range from clustering and spech recognition to DNA and biological and social network analysis. Since structure problems include complicated relationships between variables, it pays to introduce a formal method for describing such relationships, called graphical models.}

\include{clustering}
\include{hmm}
\chapter{Recommendation systems}
\include{networks}
\include{recommendation}

\chapter{Bandit problems}
\include{bandit}
\include{experiment-design}

\chapter{Markov decision procesess}
\include{mdp}

\include{safety}


\bibliographystyle{plainnat}
\bibliography{../bibliography}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:
