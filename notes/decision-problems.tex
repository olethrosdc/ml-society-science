\chapter{Decision and Learning Theory}
\label{ch:decision-problems}
\only<article>{This chapter deals with simple decision problems,
  whereby a decision maker (DM) makes a simple choice among many. In
  some of this problems the DM has to make a decision after first
  observing some side-information. Then the DM uses a \emph{decision
    rule} to assign a probability to each possible decision for each
  possible side-information. However, designing the decision rule is
  not trivial, as it relies on previously collected data. A
  higher-level decision includes choosing the decision rule
  itself. The problems of classification and regression fall within
  this framework. While most steps in the process can be automated and
  formalised, a lot of decisions are actual design choices made by
  humans. This creates scope for errors and misinterpretation of
  results.

  In this chapter, we shall formalise all these simple decision
  problems from the point of view of statistical decision theory. The
  first question is, given a real world application, what type of
  decision problem does it map to? Then, what kind of machine learning
  algorithms can we use to solve it? What are the underlying
  assumptions and how valid are our conclusions?  }

\section{Hierarchies of decision making problems}
\label{sec:decision-problems}
\only<presentation>{
  \begin{frame}
    \tableofcontents[ 
    currentsection, 
    hideothersubsections, 
    sectionstyle=show/shaded
    ] 
  \end{frame}
}


\only<article>{ All machine learning problems are essentially decision
  problems. This essentially means replacing some human decisions with
  machine decisions. One of the simplest decision problems is
  classification, where you want an algorithm to decide the correct
  class of some data, but even within this simple framework there is a
  multitude of decisions to be made. The first is how to frame the
  classification problem the first place. The second is how to
  collect, process and annotate the data. The third is choosing the
  type of classification model to use. The fourth is how to use the
  collected data to find an optimal classifier within the selected
  type. After all this has been done, there is the problem of
  classifying new data. In this course, we will take a holistic view
  of the problem, and consider each problem in turn, starting from the
  lowest level and working our way up.}


\subsection{Simple decision problems}
\begin{frame}
  \frametitle{Preferences}
  \only<article>{The simplest decision problem involves selecting one item from a set of choices, such as in the following examples}  
  \begin{example}
    \begin{block}{Food}
      \begin{itemize}
      \item[A] McDonald's cheeseburger
      \item[B] Surstromming
      \item[C] Oatmeal
      \end{itemize}
    \end{block}
    \begin{block}{Money}
      \begin{itemize}
      \item[A] 10,000,000 CHF
      \item[B] 10,000,000 USD
      \item[C] 1,000 BTC
      \end{itemize}
    \end{block}
    \begin{block}{Entertainment}
      \begin{itemize}
      \item[A] 1 Week in Venice
      \item[B] 1 Week Hoch-Tour in the Alps
      \item[C] 1 Week Transatlantic Cruise
      \end{itemize}
    \end{block}
  \end{example}
\end{frame}

\begin{frame}
  \frametitle{Rewards and utilities}
  \only<article>{In the decision theoretic framework, the things we
    receive are called rewards, and we assign a utility value to each
    one of them, showing which one we prefer.}
  \begin{itemize}
  \item Each choice is called a \alert{reward} $r \in \CR$.
  \item There is a \alert{utility function} $U : \CR \to \Reals$, assigning values to reward.
  \item We (weakly) prefer $A$ to $B$ iff $U(A) \geq U(B)$.
  \end{itemize}
  \only<article>{In each case, given $U$ the choice between each reward is trivial. We just select the reward:
    \[
    r^* \in \argmax_r U(r)
    \]
    The main difficult is actually selecting the appropriate utility
    function. In a behavioural context, we simply assume that humans
    act with respect to a specific utility function. However, figuring
    out this function from behavioural data is non trivial. ven when
    this assumption is correct, individuals do not have a common
    utility function.  }
  \begin{exercise}
    From your individual preferences, derive a \alert{common utility
      function} that reflects everybody's preferences in the class for
    each of the three examples. Is there a simple algorithm for
    deciding this? Would you consider the outcome fair?
  \end{exercise}
\end{frame}

\begin{frame}
  \frametitle{Preferences among random outcomes}
  \begin{example}
    Would you rather \ldots
    \begin{itemize}
    \item[A] Have 100 EUR now?
    \item[B] Flip a coin, and get 200 EUR if it comes heads?
    \end{itemize}    
  \end{example}
  \uncover<2->{
    \begin{block}{The expected utility hypothesis}
      Rational decision makers prefer choice $A$ to $B$ if
      \[
      \E(U | A) \geq \E(U | B),
      \]
      where the expected utility is
      \[
      \E(U | A) = \sum_r U(r) \Pr(r | A).
      \]
    \end{block}
    In the above example, $r \in \{0, 100, 200\}$ and $U(r)$ is
    increasing, and the coin is fair.
  }
  \begin{block}{Risk\index{risk} and monetary rewards}
    \only<article>{When $r \in \Reals$, as in the case of monetary rewards, we can use the shape of the utility function determines the amount of risk aversion. In particular:}
    \begin{itemize}
    \item<3-> If $U$ is convex, we are risk-seeking. \only<article>{In the example above, we would prefer B to A, as the expected utility of B would be higher than A, even though they give the same amount of money on average.}
    \item<4-> If $U$ is linear, we are risk neutral. \only<article>{In the example above, we would be indifferent between $A$ and $B$, as the expected amount of money is the same as the amount of money we get.}
    \item<5-> If $U$ is concave, we are risk-averse. \only<article>{Hence, in the example above, we prefer A.}
    \end{itemize}
  \end{block}
  \only<article>{This idea of risk can be used with any other utility function. We can simply replace the original utility function $U$ with a monotonic function $f(U)$ to achieve risk-sensitive behaviour. However, this is not the only risk-sensitive approach possible.}
\end{frame}


\begin{frame}
  \frametitle{Uncertain rewards}
  \only<article>{However, in real life, there are many cases where we can only choose between uncertain outcomes. The simplest example are lottery tickets, where rewards are essentially random. However, in many cases the rewards are not really random, but simply uncertain. In those cases it is useful to represent our uncertainty with probabilities as well, even though there is nothing really random.}
  \begin{itemize}
  \item Decisions $\decision \in \Decision$
  \item Each choice is called a \alert{reward} $r \in \CR$.
  \item There is a \alert{utility function} $U : \CR \to \Reals$, assigning values to reward.
  \item We (weakly) prefer $A$ to $B$ iff $U(A) \geq U(B)$.
  \end{itemize}

  \begin{example}
    \begin{columns}
      \begin{column}{0.5\textwidth}
        You are going to work, and it might rain.  What do you do?
        \begin{itemize}
        \item $\decision_1$: Take the umbrella.
        \item $\decision_2$: Risk it!
        \item $\outcome_1$: rain
        \item $\outcome_2$: dry
        \end{itemize}
      \end{column}
      \begin{column}{0.5\textwidth}
        \begin{table}
          \centering
          \begin{tabular}{c|c|c}
            $\Rew(\outcome,\decision)$ & $\decision_1$ & $\decision_2$ \\ %ro: U has only one argument.
            \hline
            $\outcome_1$ & dry, carrying umbrella & wet\\
            $\outcome_2$ & dry, carrying umbrella & dry\\
            \hline
            \hline
            $U[\Rew(\outcome,\decision)]$ & $\decision_1$ & $\decision_2$ \\
            \hline
            $\outcome_1$ & 0 & -10\\
            $\outcome_2$ & 0 & 1
          \end{tabular}
          \caption{Rewards and utilities.}
          \label{tab:rain-utility-function}
        \end{table}

        \begin{itemize}
        \item<2-> $\max_\decision \min_\outcome U = 0$
        \item<3-> $\min_\outcome \max_\decision U = 0$
        \end{itemize}
      \end{column}

    \end{columns}
  \end{example}
\end{frame}



\begin{frame}
  \frametitle{Expected utility}
  \[
  \E (U \mid a) = \sum_r U[\Rew(\outcome, \decision)] \Pr(\outcome \mid \decision)
  \]
  \begin{example}%ro: rather an exercise?
    You are going to work, and it might rain. The forecast said that
    the probability of rain $(\outcome_1)$ was $20\%$. What do you do?
    \begin{itemize}
    \item $\decision_1$: Take the umbrella.
    \item $\decision_2$: Risk it!
    \end{itemize}
    \begin{table}
      \centering
      \begin{tabular}{c|c|c}
        $\Rew(\outcome,\decision)$ & $\decision_1$ & $\decision_2$ \\ %ro: U has only one argument.
        \hline
        $\outcome_1$ & dry, carrying umbrella & wet\\
        $\outcome_2$ & dry, carrying umbrella & dry\\
        \hline
        \hline
        $U[\Rew(\outcome,\decision)]$ & $\decision_1$ & $\decision_2$ \\
        \hline
        $\outcome_1$ & 0 & -10\\
        $\outcome_2$ & 0 & 1\\
        \hline
        \hline
        $\E(U \mid \decision)$ & 0 &  -1.2 \\ 
      \end{tabular}
      \caption{Rewards, utilities, expected utility for $20\%$ probability of rain.}
      \label{tab:rain-utility-function}
    \end{table}
  \end{example}
\end{frame}





\subsection{Decision rules}

\only<article>{We now move from simple decisions to decisions that
  depend on some observation. We shall start with a simple problem in applied meteorology. Then we will discuss hypothesis testing as a decision making problem. Finally, we will go through an exercise in Bayesian methods for classification.}

\begin{frame}
  \frametitle{Bayes decision rules}
  Consider the case where outcomes are independent of decisions:
  \[
  \util (\bel, \decision) \defn \sum_{\model}  \util (\model, \decision) \bel(\model)
  \]
  This corresponds e.g. to the case where $\bel(\model)$ is the belief about an unknown world.
  \begin{definition}[Bayes utility]
    \label{def:bayes-utility}
    The maximising decision for $\bel$ has an expected utility equal to:
    \begin{equation}
      \BUtil(\bel) \defn \max_{\decision \in \Decision} \util (\bel, \decision).
      \label{eq:bayes-utility}
    \end{equation}
  \end{definition}
\end{frame}




\begin{frame}
  \frametitle{The $n$-meteorologists problem}
  \index{$n$-meteorologists|textbf}
  \only<article>{Of course, we may not always just be interested in classification performance in terms of predicting the most likely class. It strongly depends on the problem we are actually wanting to solve. In  biometric authentication, for example, we want to guard against the unlikely event that an impostor will successfully be authenticated. Even if the decision rule that always says 'OK' has the lowest classification error in practice, the expected cost of impostors means that the optimal decision rule must sometimes say 'Failed' even if this leads to false rejections sometimes.}
  \begin{exercise}
    \only<presentation>{
      \only<1>{
        \begin{itemize}
        \item Meteorological models $\CM = \set{\model_1, \ldots, \model_n}$
        \item Rain predictions at time $t$: $p_{t,\model} \defn  P_{\model}(x_t = \textrm{rain})$.
        \item Prior probability $\bel(\model) = 1/n$ for each model.
        \item Should we take the umbrella?
        \end{itemize}
      }
    }
    \only<article>{Assume you have $n$ meteorologists. At each day $t$, each meteorologist $i$ gives a probability $p_{t,\model_i}\defn P_{\model_i}(x_t = \textrm{rain})$ for rain. Consider the case of there being three meteorologists, and each one making the following prediction for the coming week. Start with a uniform prior $\bel(\model) = 1/3$ for each model.}
    {
      \begin{table}[h]
        \begin{tabular}{c|l|l|l|l|l|l|l}
          &M&T&W&T&F&S&S\\
          \hline
          CNN & 0.5 & 0.6 & 0.7 & 0.9 & 0.5 & 0.3 & 0.1\\
          SMHI & 0.3 & 0.7 & 0.8 & 0.9 & 0.5 & 0.2 & 0.1\\
          YR & 0.6 & 0.9 & 0.8 & 0.5 & 0.4 & 0.1 & 0.1\\
          \hline
          Rain? & Y & Y & Y & N & Y & N & N
        \end{tabular}
        \caption{Predictions by three different entities for the probability of rain on a particular day, along with whether or not it actually rained.}
        \label{tab:meteorologists}
      \end{table}
    }
    \uncover<2->{
      \begin{enumerate}
      \item<2-> What is your belief about the quality of each meteorologist after each day? 
      \item<3-> What is your belief about the probability of rain each day? 
        \[
        P_\bel(x_t = \textrm{rain} \mid x_1, x_2, \ldots x_{t-1})
        =
        \sum_{\model \in \Model} P_\model(x_t = \textrm{rain} \mid x_1, x_2, \ldots x_{t-1})
        \bel(\model \mid x_1, x_2, \ldots x_{t-1}) 
        \]
      \item<4-> Assume you can decide whether or not to go running each
        day. If you go running and it does not rain, your utility is 1. If
        it rains, it's -10. If you don't go running, your utility is
        0. What is the decision maximising utility in expectation (with respect to the posterior) each
        day?
      \end{enumerate}
    }
    \label{ex:meteorologists}
  \end{exercise}
\end{frame}


\input{bayes} % Bayesian inference
\input{statistical-testing} % Missing
\input{classification}
\input{naive-bayes} % naive Bayes classifiers
\input{knn}  % knn, reproducability and bootstrapping
\input{ann} % linear models and stochastic gradient descent



\begin{frame}
  \frametitle{Learning outcomes}
  \begin{block}{Understanding}
    \begin{itemize}
    \item Preferences, utilities and the expected utility principle.
    \item Hypothesis testing and classification as decision problems.
    \item How to interpret $p$-values Bayesian tests.
    \item The MAP approximation to full Bayesian inference.
    \end{itemize}
  \end{block}
  
  \begin{block}{Skills}
    \begin{itemize}
    \item Being able to implement an optimal decision rule for a given utility and probability.
    \item Being able to construct a simple null hypothesis test.
    \end{itemize}
  \end{block}

  \begin{block}{Reflection}
    \begin{itemize}
    \item When would expected utility maximisation not be a good idea?
    \item What does a $p$ value represent when you see it in a paper?
    \item Can we prevent high false discovery rates when using $p$ values?
    \item When is the MAP approximation good?
    \end{itemize}
  \end{block}
  
\end{frame}






%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:

