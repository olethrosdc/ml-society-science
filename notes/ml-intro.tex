\chapter{Introduction}
\label{ch:introduction}



\section{Introduction to machine learning}
\only<presentation>{
  \begin{frame}
    \tableofcontents[ 
    currentsection, 
    hideothersubsections, 
    sectionstyle=show/shaded
    ] 
  \end{frame}
}


\only<article>{
  % What are the central problems in machine learning?
  Problems in machine learning are similar to problems in science.
  Scientists must plan experiments intelligently and collect data.
  The must be able to use the data to verify or falsify different
  hypotheses.  More generally, they must be able to make decisions
  under uncertainty (Without uncertainty, there would be no need to
  gather more data).  Similar problems appear in more mundane tasks,
  like learning to drive a car.  There are always two aspects to the
  problem: first, narrowing down the set of plausible hypotheses from
  the data, and actively experimenting in such a way as to learn as
  quickly as possible.  }
\only<presentation>{
  \begin{frame}
    \frametitle{Scientific applications}
    \centering
    \begin{columns}
      \begin{column}{0.5\textwidth}
        \centering
        \includegraphics[width=0.8\columnwidth]{../figures/climate.jpg}\\
        \includegraphics[width=\columnwidth]{../figures/networks-2.jpg}
      \end{column}
      \begin{column}{0.5\textwidth}
        \includegraphics[width=\columnwidth]{../figures/dark_matter.jpg}
        \\
        \includegraphics[width=\columnwidth]{../figures/protein.jpg}
      \end{column}
    \end{columns}
    \only<2>{
      \begin{tikzpicture}[remember picture,overlay]
        \draw[fill=black,opacity=0.75] 
        (current page.north east) rectangle (current page.south west);
        \node at (current page.center) {
          {\Huge \alert{Interpretability, Reproducibility}}
        };
      \end{tikzpicture}}
  \end{frame}
}

\only<article>{
  For that reason, science is a very natural application area for
  machine learning.  We can model the effects of climate change and
  how to mitigate it; discover structure in social networks; map
  the existence of dark matter in the universe by intelligently
  shifting through weak gravitational lens data, and not only study
  the mechanisms of protein folding, but discover methods to
  synthesize new drugs.

  We must be careful, however. In many cases we need to be able to
  interpret what our model tells us. We also must make sure that
  the any results we obtain are reproducible.
}

\only<presentation>{
  \begin{frame}
    \frametitle{Pervasive ``intelligent'' systems}
    \begin{columns}
      \begin{column}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../figures/echo-home.jpg}
        \\
        Home assistants

        \vspace{\fill}

        \bigskip

        \includegraphics[width=\textwidth]{../figures/tesla.jpg}
        \\
        Autonomous vehicles
      \end{column}
      \begin{column}{0.3\textwidth}
        \centering 
        \includegraphics[width=\textwidth]{../figures/web-ads.png}
        \\
        Web advertising

        \vspace{\fill}

        \bigskip

        \includegraphics[width=\textwidth]{../figures/uber-here-maps.jpg}
        \\
        Ridesharing
      \end{column}
      \begin{column}{0.3\textwidth}
        \centering 
        \\
        \includegraphics[width=\textwidth,clip = true, trim=0 0 0 42.5cm]{../figures/lending.pdf}
        \\
        Lending

        \vspace{\fill}

        \bigskip

        \includegraphics[width=\textwidth]{../figures/algorithms-public.jpg}
        \\
        Public policy
      \end{column}
    \end{columns}
    \only<2>{
      \begin{tikzpicture}[remember picture,overlay]
        \draw[fill=black,opacity=0.75] 
        (current page.north east) rectangle (current page.south west);
        \node at (current page.center) {
          {\Huge \alert{Privacy, Fairness, Safety}}
        };
      \end{tikzpicture}}
  \end{frame}
}

\only<article>{ While machine learning models in science are typically
  carefully handcrafted by scientists and experts in machine learning
  and statistics, this is not typically the case in everyday
  applications. Nevertheless, well-known or home-grown machine
  learning models are being deployed across the application
  spectrum. This involve home assistants that try and get you want;
  web advertising, which tries to find new things for you to want;
  lending, which tries to optimally lend you money so that you buy
  what you didn't need before. We also have autonomous vehicles, which
  decide how to take you were you want to go, and ridesharing
  services, which do the same thing. The latter also decide where
  which client their drivers should pick up next. Finally, there are
  many applications in public policy that including some type of
  automated decision making, partially based on machine learning and
  artificial intelligence research. These include crime prevention,
  justice, and disease control which use machine learning.  In all
  those cases, we have to worry about a great many things that are
  outside the scope of the machine learning problems itself. These are
  (a) privacy: you don't want your data used in ways that you have not
  consented to, especially if this may cause harm (b) fairness: you
  don't want minorities to be disadvantaged, or to enable nepotism and
  (c) safety: you don't want your car to crash.  }

\section{Data analysis,  learning and planning}

\only<article>{
  To make the above more concrete, let's have a look at a number of problems in machine learning. These involve learning from and analysing data, including inferring decision rules, and constructing complex plans using the evidence gleaned from the data. Machine learning problems are commonly separated into three different types: supervised, unsupervised and reinforcement learning. Typical supervised learning problems include classification and regression, while unsupervised problems include compression, clustering and topic modelling. Reinforcement learning, on the other hand, is concerned with artificially intelligent agents more generally, with examples including game playing and adaptive control. There are a few basic differences between those learning problems. Firstly, the \emph{measure} of performance, and the \emph{type} of feedback we have about learning performance. In supervised learning, there is both a clear objective, and a very simple feedback mechanism for every decision you make. In unsupervised problems, the objective is sometimes not easy to formalise, however once this is done there is no need for a feedback mechanism. In reinforcement learning problems, the performance metric is simple to understand, but measuring performance is not easy, as the feedback we have is delayed and indirect. A final aspect is whether or not the problem involves \emph{active data collection}. While this is always necessary in reinforcement learning problems, standard supervised and unsupervised learning involve either a fixed dataset or a constant stream of data, which is not influenced by the algorithm. In this course, we will try and take a global view of these problems in the context of decision theory.
}

\only<presentation>{
  \begin{frame}
    \centering
    \Huge{What can machine learning do?}
  \end{frame}
}
\begin{frame}
  \frametitle{Can machines learn from data?}
  \begin{center}
    \only<1>{\includegraphics[width=0.8\textwidth]{../figures/text-cloud}
      \\

      {\large An unsupervised learning problem: topic modelling}
    }
    \only<2>{\includegraphics[width=0.8\textwidth]{../figures/Face-Recognition}
      \\

      {\large A supervised learning problem: object recognition}
    }
  \end{center}
\end{frame}


\only<article>{
  You can use machine learning just to analyse, or find structure in
  the data. This is generally called unsupervised learning. One such
  example is topic modelling, where you let the algorithm find topics
  from a corpus of text.  These days machines are used to learn from
  in many applications.  These include speech recognition, facial
  authentication, weather prediction, etc. In general, in these
  problems we are given a \emph{labelled} dataset with, say, example
  images from each class. Unfortunately this does not scale very
  well, because obtaining labels is expensive.

  This is partially how science works, because what we need to do
  is to find a general rule of nature from data. Starting from some
  hypothesis and some data, we reach a conclusion. However, many
  times we may need to actively experiment to obtain more data,
  perhaps because we found that our model is wrong.
}



\begin{frame}
  \frametitle{Can machines learn from their mistakes?}
  \begin{center}
    \includegraphics[width=0.7\textwidth]{../figures/rl_interaction}
  \end{center}
  \only<presentation>{
    \begin{block}{Reinforcement learning}
      Take actions $a_1, \ldots, a_t$, so as to maximise utility
      $U = \sum_{t=1}^T r_t$
    \end{block}
  }
\end{frame}


\only<article>{
  So, what happens when we make a mistake? Can we somehow recognise
  it? Humans and other animals can actually learn from their
  mistakes. Consider the proverbial rat in the maze. At some
  intervals, the experimenter places some cheese in there, and the
  rat must do a series of actions to obtain it, such as navigating
  the maze and pulling some levers. It doesn't know how to get to
  the cheese easily, but it slowly learns the layout of the maze
  through observation, and in the end, through trial-and-error it
  is able to get to the cheese very efficiently.

  We can formalise this as a reinforcement learning problem, where
  the rat takes a series of actions; at each step it also obtains a
  reward, let's say equal to 0 when it has no cheese, and 1 when it
  eats cheese. Then we can declare that the rat's utility is the sum
  of all rewards over time, i.e. the total amount of cheese it can
  eat before it dies. The rat needs to explore the environment in order to be able to
  get to the cheese. 

  An example in robotics is trying to teach a
  robot to flip pancakes. One easy thing we can try is to show the robot
  how to do it, and then let it just copy the demonstrated
  movement. However, this doesn't work! The robot needs to explore
  variations of the movement, until it manages to successfully flip
  pancakes. Again, we can formulate this as a reinforcement learning
  problem, with a reward that is high whenever the pancake's position is
  flipped, and on the pan; and low everywhere else. Then the robot can
  learn to perform this behaviour through trial and error. It's
  important to note that in this example, merely demonstration is not
  enough. Neither is reinforcement learning enough. The same thing is
  true for the recent success of AlphaGo in beating a master human:
  apart from planning, they used both demonstration data and self-play,
  so that it could learn through trial and error.  }

\begin{frame}
  \frametitle{Can machines make complex plans?}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{../figures/619px-FloorGoban}
  \end{center}
\end{frame}


\only<article>{
  I suppose the first question is whether machines can plan
  ahead. Indeed, even for large problems, such as Go, machines can
  now perform at least as well as top-rated humans. How is this
  achieved?
}

\begin{frame}
  \frametitle{Machines can make complex plans!}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{../figures/Tic-tac-toe-game-tree}
  \end{center}
\end{frame}


\only<article>{
  The basic construction is the planning tree. This is an enumeration
  of all possible future events. If a complete enumeration is
  impossible, a partial tree is constructed. However this requires
  evaluating non-terminal game positions. In the old times, this was
  done with heuristics, but now this is data-driven, both through the
  use of expert databases, and through self-play and reinforcement
  learning.
}


\subsection{Experiment design}

\only<presentation>{
  \begin{frame}
    \centering
    \Huge{The scientific process as machine learning}
  \end{frame}
  \begin{frame}
    \centering
    \includegraphics[width=\textwidth]{../figures/Las_Vegas_slot_machines}
  \end{frame}
}


\only<article>{
  An example that typifies trial and error learning are bandit
  problems. Imagine that you are in a Casino and you wish to
  maximise the amount of money you make during the night. There are
  a lot of machines to play. If you knew which one was the best,
  then you'd just play it all night long. However, you must also
  spend time trying out different machines, in order to get an
  estimate of how much money each one gives out. The trade off
  between trying out different machines and playing the one you
  currently think is best is called the exploration-exploitation
  trade-off and it appears in many problems of experiment design for
  science.
}


\only<presentation>{
  \begin{frame}
    \frametitle{Adam, the robot scientist}
    \centering
    \includegraphics[width=\fwidth]{../figures/robot-scientist}
  \end{frame}
}

\only<article>{
  Let's say we want to build a robot scientist and tell it to
  discover a cure for cancer. What does the scientist do and how can the robot replicate it??
}


\only<presentation>{
\begin{frame}
  \frametitle{Drug discovery}
  \centering
  \includegraphics[width=\columnwidth]{../figures/drug-discovery-000}
\end{frame}
}

\only<article>{
  Simplifying the problem a bit, consider that you have a large
  number of drug candidates for cancer and you wish to discover
  those that are active against it. The ideas is that you select
  some of them, then screen them, to sort them into active and
  inactive. However, there are too many drugs to screen, so the
  process is interactive. At each cycle, we select some drugs to
  screen, classify them, and then use this information to select
  more drugs to screen. This cycle, consequently has two parts:
  1. Selecting some drugs given our current knowledge.
  2. Updating our knowledge given new evidence.
}


\begin{frame}
  \frametitle{Drawing conclusions from results}
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}[line width=2pt]
      \node at (0,0) (bt) {hypothesis}; \node[select] at (0,2) (at)
      {experiment}; \node[utility] at (3,-2) (rt) {result};
      \draw[blue,->] (at) -- (rt); \node at (4,0) (bt2) {conclusion};
      \draw[red,->] (at) -- (bt2); \draw[red,->] (bt) -- (bt2);
      \draw[red,->] (rt) -- (bt2);
    \end{tikzpicture}
    \only<article>{
      \caption{Dependence diagram between selection of an experiment, formulation of a hypothesis, and drawing of a conclusion. The result depends only on the experiment. However, the conclusion depends on the experiment, hypothesis and the obtained result. The red lines indicate computational dependencies, while the blue lines indicate physical dependencies.}
    }
    \label{fig:drawing-conclusions}
  \end{figure}
\end{frame}

\only<article>{
  In general, we would like to have some method which can draw
  conclusions from results. This involves starting with a
  hypothesis, performing an experiment to verify or refute it,
  obtain some experimental result; and then concluding for or
  against the hypothesis. Here the arrows show dependencies
  between these variables. So what do we mean by "hypothesis" in this case?
}
\subsection{Inference.}
\only<presentation>{
\begin{frame}
  \frametitle{Tycho Brahe's minute eye measurements}
  \begin{figure}[h]
    \centering
    \begin{columns}
      \begin{column}{0.45\textwidth}
        \includegraphics[width=0.5\fwidth]{../figures/circular-orbits}
      \end{column}
      \hspace{1em}
      \begin{column}{0.45\textwidth}
        \includegraphics[width=0.5\fwidth]{../figures/tycho-observations}
      \end{column}
    \end{columns}

    \caption{Tycho's measurements of the orbit of Mars and the conclusion about the actual orbits, under the assumption of an earth-centric universe with circular orbits.}
    \label{fig:tycho}
  \end{figure}
  \begin{itemize}
  \item Hypothesis: Earth-centric, Circular orbits
  \item Conclusion: \alert{Specific} circular orbits
  \end{itemize}
\end{frame}
}

\only<article>{
  Let's take the example of planetary orbits. Here Tycho famously
  spent 20 years experimentally measuring the location of Mars. He
  had a hypothesis: that planetary orbits were circular, but he
  didn't know which were the right orbits. When he tried to fit his data to this hypothesis, he concluded a specific circular orbit for Mars \ldots around Earth.
}

\only<presentation>{
  \begin{frame}
  \frametitle{Johannes Kepler's alternative hypothesis}
  \begin{columns}
    \centering
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\fwidth]{../figures/orbits}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\fwidth]{../figures/tycho-observations}
    \end{column}
  \end{columns}
    \begin{itemize}
    \item Hypothesis: Circular \alert{or} elliptic orbits
    \item Conclusion: Specific \alert{elliptic} orbits
    \end{itemize}
\end{frame}
}

\only<article>{
  \begin{figure}[h]
      \centering

    \begin{subfigure}{0.3\textwidth}
      \includegraphics[width=0.5\fwidth]{../figures/tycho-observations}
      \caption{Tycho's Measurements}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
      \includegraphics[width=0.5\fwidth]{../figures/circular-orbits}
      \caption{Tycho's conclusion}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
      \includegraphics[width=0.5\fwidth]{../figures/orbits}
      \caption{Kepler's conclusion}
    \end{subfigure}
    \caption{How given the same data, one can reach different conclusion depending on one's modelling assumptions.}
  \end{figure}
}

\only<article>{
  Kepler had a more general hypothesis: that orbits could be
  circular or elliptic, and he actually accepted that the planets
  orbited the sun. This led him to the broadly correct model of all
  planets being in elliptical orbits around the sun. However, the
  actual verification that all things do not revolve around earth,
  requires different experiments.
}


\only<presentation>{
  \begin{frame}
    \frametitle{200 years later, Gauss formalised this statistically}
    \begin{columns}
      \begin{column}{0.5\textwidth}
        \includegraphics[width=\fwidth]{../figures/gauss-diagram}
      \end{column}
      \begin{column}{0.5\textwidth}
        \includegraphics[width=\fwidth]{../figures/SeptemberTable}
      \end{column}
    \end{columns}
  \end{frame}
}

\only<article>{
  Later on, Gauss collected even more experimental data to calculate the orbit of Ceres. He did this using one of the first formal statistical methods; this allowed him to avoid cheating (like Kepler did, to accentuate his finding that orbits were elliptical).
}

\only<presentation>{
  \begin{frame}
    \frametitle{A warning: The dead salmon mirage}
    \includegraphics[width=\textwidth]{../figures/fmri-salmon}
  \end{frame}
}


\only<article>{
  It is quite easy to draw the wrong conclusions from applying
  machine learning / statistics to your data. For example, it was
  fashionable to perform fMRI studies in humans to see whether some
  neurons have a particular functional role. There were even
  articles saying that "we found the neurons encoding for Angelina
  Jolie". So some scientists tried to replicate those results. They
  took a dead salmon, and put it an fMRI scanner. They checked its
  brain activity when it was shown images of happy or sad
  people. Perhaps surprisingly, they found an area of the brain that
  was correlated with the pictures - so it seemed, as though the
  dead salmon could distinguish photos of happy people from sad
  ones. However, this was all due to a misapplication of
  statistics. In this course, we will try and teach you to avoid
  such mistakes.

}

\begin{frame}
  \frametitle{A simple simulation study}
  \only<article>{Sometimes we want to use a simple simulation study to understand how well our methods work. The following code is an example of how to do this. Here we are doing a simplified fMRI analysis, but the general idea is not significhey, antly different from what people actually do in the field.}
  \url{src/reproducibility/mri_analysis.ipynb}
\end{frame}

\begin{frame}
  \frametitle{Planning future experiments}
  \only<article>{
    So far we have focused only on the problem of data analysis. However, we also need to think about the problem of planning for experiments. This is called \alert{experiment design}. Experiment designs are usually fixed. In that case, we can use assumptions about the data and how much accuracy we need to design the experiment. However, it is also possible to have an adaptive experiment design where our future experiments depend on our current conclusions.
  }
  \begin{figure}
    \centering
    \begin{tikzpicture}[line width=2pt]
      \node at (0,0) (bt) {hypothesis};
      \node[select] at (0,2) (at) {experiment};
      \node[utility] at (3,-2) (rt) {result};
      \draw[blue,->] (at) -- (rt);
      \node at (4,0) (bt2) {conclusion};
      \draw[red,->] (at) -- (bt2);
      \draw[red,->] (bt) -- (bt2);
      \draw[red,->] (rt) -- (bt2);
    \end{tikzpicture}
  \end{figure}
\end{frame}

\only<article>{
  In general, optimal experiment design is indeed difficult, especially in setting such as drug discovery where the number of experiments is huge.  However, conceptually, there is a simple and elegant solution to this problem.
}


\begin{frame}
  \frametitle{Planning experiments is like Tic-Tac-Toe}
  \begin{center}
    \includegraphics[width=\textwidth]{../figures/Tic-tac-toe-game-tree}
  \end{center}
\end{frame}


\only<article>{
  The basic idea is to think of experiment design as a game between the scientist and Nature. At every step, the scientist plays an X to  denote an experiment. Then Nature responds with an Observation. The main difference from a game is that Nature is (probably) not adversarial. We can also generalise this idea to problems in robotics, etc.
}

\only<presentation>{
  \begin{frame}
    \frametitle{Eve, another robot scientist}
    \includegraphics[width=\textwidth]{../figures/eve.jpg}
    Discovered a malaria drug
  \end{frame}
}
\only<article>{
  These kinds of techniques, coming from the reinforcement learning literature have been successfully used at the university of Manchester to create a robot, called Eve, that recently (re)-discovered a malaria drug.
}

\section{Book overview}



\only<presentation>{
  \begin{frame}
    \frametitle{Machine learning in practice}
    \begin{block}{Avoiding pitfalls}
      \begin{itemize}
      \item Choosing hypotheses.
      \item Correctly interpreting conclusions.
      \item Using a good testing methodology.
      \end{itemize}
    \end{block}
    \begin{block}{Machine learning in society}
      \begin{itemize}
      \item<alert@2> Privacy \uncover<2->{--- Credit risk.}
      \item<alert@3> Fairness \uncover<3->{--- Job market.}
      \item<alert@4> Safety \uncover<4->{--- Medicine.}
      \end{itemize}
    \end{block}
  \end{frame}
}

\only<article>{ While in the past machine learning was mainly a field
  of research, with only some applications, but now machine learning
  is pervasive: Our phones, cars, watches, doorbells, kettles are
  connected to the internet and send a continuous stream of data to
  companies. In addition, many companies and government actors use
  machine learning algorithms to make or support decisions. This
  creates a number of problems in privacy, fairness and safety.  }


\begin{frame}
  \frametitle{The view from statistics}
  \only<article>{While in machine learning people generally discuss mainly supervised, unsupervised or reinforcement learning, these are actually three rather broad, but still limited categories of problems. There are many other problems, such as semi-supervised learning, active learning, imitation/apprenticeship learning, inverse reinforcement learning, preference elicitation, adaptive control, and possibly many others to come. The statistical view is that there basically three types of problems:}

  \paragraph{Inference.}\index{inference|textbf}
    Given what we know, what can we say about how the world works, the current state of the world or events in the past?
  \paragraph{Prediction.}\index{prediction|textbf}
    Can we predict specific evens in the future? \only<article>{This frequently is done through some type of inference.}
  \paragraph{Decision making.}\index{prediction|textbf}
    Given what we know, and what we want to achieve, what is the best decision we can make? \only<article>{This typically requires some ability to predict the effect of our actions.}
  \only<article>{We will encounter many specific inference, prediction and decision making tasks during this course.}
\end{frame}

\only<presentation>{
\begin{frame}
  \frametitle{Course structure}
  \begin{block}{Module structure}
    \begin{itemize}
    \item \alert{Activity}-based, hands-on.
    \item Mini-lectures with short exercises in each class.
    \item Technical tutorials and labs in alternate week.
    \end{itemize}
  \end{block}
  
  \begin{block}{Modules}
    Three mini-projects.
    \begin{itemize}
    \item Simple decision problems: Credit risk.
    \item Sequential problems: Medical diagnostics and treatment.
    \end{itemize}
  \end{block}
\end{frame}
}

\begin{frame}
  \frametitle{Technical topics}
  The book covers a number of technical topics. Sections marked with an asterisk (*) may be skipped safely upon a first reading without compromising understanding of the remaining material.
  \begin{block}{Machine learning problems}
    \begin{itemize}
    \item Unsupervised learning. \only<article>{Loosely speaking, this is simply the problem of estimating some structure from data. In statistical terms, it is usually the problem of estimating some joint distribution of random variables under some model assumptions. Problems in unsupervised learning include clustering, anomaly detection, compression}.
    \item Supervised learning. \only<article>{In this setting data can be split in two groups of variables. One group that is always available, and another group that must be predicted. A special case of the problem is when we wish to estimate some function $f : \CX \to \CY$ from data. Classical problems in this setting are classification and regression.}
    \item Reinforcement learning. \only<article>{This is a very general sequential decision problem, where an agent must learn how to behave optimally in an unknown environment only by limited feedback and reinforcement. The standard setting involves the agent trying to maximise its (expected) cumulative reward over time.}
    \end{itemize}
  \end{block}

  \begin{block}{Algorithms and models}
    \begin{itemize}
    \item Bayesian inference and decision theory. \only<article>{We will cover the basic ideas of probabilistic graphical models and decision diagrams more generally. These allow us to formalise statistical inference and decision problems, as well as conditional dependence relationships between variables. It is also a way for us to represent model architectures, as well as some fairness notions.}
    \item Differential privacy. \only<article>{This book focuses on an information-theoretic notion of privacy, differential privacy. This quantifies the amount of information leakage about any one person due to the public release of aggregate statistics.}
    \item Stochastic optimisation and neural networks. \only<article>{Optimisation is at the core of modern machine learning techniques. We will cover the basic of stochastic gradient descent. We will also examine neural networks from both a probabilistic and optimisation perspective.}
    \end{itemize}
  \end{block}
\end{frame}


\begin{frame}
  \begin{block}{Further reading}
    \begin{itemize}
    \item \citet{bennett2012journal} describe how the usual
      uncorrected analysis of fMRI data leads to the conclusion that
      the dead salmon can reason about human images.
    \item \citet{Bennett2009ThePC} discuss how to perform analyses of medical images in a principled way. They also introduce the use of simulations in order to test how well a particular method is going to perform.
    \end{itemize}
  \end{block}

  \begin{block}{Resources}
    \begin{itemize}
    \item Course code and notes:  \url{https://github.com/olethrosdc/ml-society-science}
    \item Book: \url{https://github.com/olethrosdc/ml-society-science/book.pdf}
    \end{itemize}
  \end{block}
\end{frame}





%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "book.tex"
%%% End: 
