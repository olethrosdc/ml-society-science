* Artificial Intelligence, Science and Society

- ECTS Credits: 6.
- Expected development time: 400 hours (200 for the lecture notes and 200 for the assignments, tutorials and projects)
- Teaching time: 264-384 hours (48 contact, 96 preparation, 120-240 corrections for 20-40 students)

** Learning outcomes

There are two types of learning outcomes. Firstly, those that are the core of the course, and secondly methodologies that are used as part of the course.

Core learning outcomes:

1. Ensuring reproducibility in both science and AI development.
2. Recognising privacy issues and be able to mitigate them using appropriate formalisms.
3. Mitigating issues with potential fairness and discrimination when algorithms are applied at scale.
4. Applying AI algorithms to the world wide web.
5. Developing adaptive experimental design protocols for online and scientific applications.
6. Understanding when it is possible provide safety guarantees for AI algorithms.

AI learning outcomes:

1. Understanding how to use data for learning, estimation and testing to create reproducible research.
2. Understanding Bayesian inference and decision theory and being able to develop graphical models.
3. Understanding neural networks and how to apply stochastic optimisation algorithms.
4. Understanding and using differential privacy as a formalism.
5. Understanding the recommendation problem and how to use filtering and bandit algorithms.
6. Understanding the reinforcement learning problem and how to approximately make sequentially optimal decisions.


** Course content

The course is split in 6 sessions, which should be taken in sequence.

Module 1. Project: Credit Risk.

Session 1. Reproducibility: kNN, bootstrapping, Bayesian inference, decision problems, false discovery.
Session 2. Fairness: Decision diagrams, conditional independence, meritocracy, discrimination.

Module 2. Project: Recommendation systems and fake news.

Session 3. Privacy: Databases, k-anonymity, graphical models, differential privacy, the reusable holdout.
Session 4. The web: Recommendation systems, clustering, latent variable models, fake news.

Module 3. Project: Medical diagnostics.

Session 5. Adaptive experiment design: Bandit problems, stochastic optimisation, Markov decision processes, dynamic programming, reinforcement learning
Session 6. Safety: Aletorial and epistemic risk, confidence bounds, interventions, counterfactuals and causality.

** Examination

There are 6 small assingments, taking 2-4 hours each (partly done in a
tutorial session) and 3 mini-projects, taking 8-16 hours each (partly
done in a lab session). A 15-min oral exam (possibly online) is conducted based on the
project reports.

** Motivation

Algorithms from Artificial Intelligence are becoming ever more complicated and are used in manifold ways in today's society: from prosaic applications like web advertising to scientific research. Their indiscriminate use creates many externalities that can be, however, precisely quantified and mitigated against.

The purpose of this course is to familiarise students with societal and scientific effects due to the use of artificial intelligence at scale. It will equip  students with all the requisite knowledge to apply state-of-the-art machine learning tools to a problem, while recognising potential pit-falls. The focus of the course is not on explaining a large set of models. It uses three basic types of models for illustration: k nearest-neighbour, neural networks and probabilistic graphical models, with an emphasis on the latter for interpretability and the first for lab work. It is instead on the issues of reproducibility, data colletion and experiment design, privacy, fairness and safety when applying machine learning algorithms. For that reason, we will cover technical topics not typically covered in an AI course: false discovery rates, differential privacy, fairness, causality and risk. Some familiarity with machine learning concepts and artificial intelligence is expected, but not necessary.
 
My background is ideally suited for this course as I have been working on automated experiment design, reinforcement learning, privacy, fairness and safety. I have given basic and advanced courses related to these topics in various universities.

* Lecture plan


** Week 1: ML Intro and interpretability
   :LOGBOOK:
   CLOCK: [2018-04-04 Wed 09:22]--[2018-04-04 Wed 10:30] =>  1:08
   CLOCK: [2018-04-03 Tue 20:58]--[2018-04-03 Tue 21:16] =>  0:18
   CLOCK: [2018-04-02 Mon 21:25]--[2018-04-02 Mon 22:25] =>  1:00
   CLOCK: [2018-03-19 mån 12:04]--[2018-03-20 tis 15:57] => 27:53
   :END:
Machine learning as science: hypotheses, experiments and conclusions.
kNN example: What is classification? What is clustering? Making sure you formalise the problem.

1. KNN.
2. Reproducibility
3. Bootstrapping
4. Decision hierarchies
5. Bayesian inference
6. Optimisation and SGD.

*** Modelling :TUTORIAL:

1. Linear models
2. Neural networks
3. Confidence and $p$-values
4. Naive Bayes: Model mismatch
5. $p$-values, cross-validation and  model mismatch


The purpose of this lecture is to familiarise students with all the
decisions made from the beginning to the end of the data science
process, and with the possible externalities when an algorithm is
applied to real data.

*** Training vs test in kNN
	:LOGBOOK:
	CLOCK: [2018-05-27 Sun 14:10]--[2018-05-27 Sun 22:01] =>  7:51
	:END:

	:LOGBOOK:
        CLOCK: [2018-06-23 Sat 14:40]--[2018-06-23 Sat 15:40] =>  1:00
	CLOCK: [2018-05-28 Mon 14:49]--[2018-05-28 Mon 23:33] =>  8:44
	CLOCK: [2018-04-06 Fri 20:46]--[2018-04-06 Fri 22:15] =>  1:29
	CLOCK: [2018-04-06 Fri 15:20]--[2018-04-06 fre 16:20] =>  1:00
	:END:


Reproducibility: Finding ‘important features’ in a small dataset.  The
fallacy of p-values.  The aim of this lecture is to introduce students
to the use and mis-use of automated decision making algorithms for
problems in science and society.


** Project start: Credit risk for mortgages. [Aim: Reproducibility, Privacy and Fairness]
** Week 2: Privacy
   :LOGBOOK:
   CLOCK: [2018-07-14 lör 10:22]--[2018-07-14 Sat 11:22] =>  1:00
   CLOCK: [2018-07-12 tor 11:07]--[2018-07-12 tor 14:09] =>  3:02
   CLOCK: [2018-07-09 Mon 14:20]--[2018-07-09 mån 15:20] =>  1:00
   CLOCK: [2018-07-07 Sat 15:14]--[2018-07-07 Sat 16:14] =>  1:00
   CLOCK: [2018-07-06 Fri 15:39]--[2018-07-06 Fri 16:39] =>  1:00
   CLOCK: [2018-04-22 sön 17:16]--[2018-04-22 sön 19:19] =>  2:03
   CLOCK: [2018-04-24 tis 16:18]--[2018-04-24 tis 16:44] =>  0:26
   :END:

1. Privacy in databases.
2. k-anonymity.
3. Differential Privacy.
4. The Random Response Mechanism. 
5. Laplace Mechanism.
6. Exponential mechanism.

The purpose of this lecture is to introduce the students to basic database concepts, as well as to privacy problems that can occur when allowing access to a database to a third party.



** Week 3: Fairness
   :LOGBOOK:
   CLOCK: [2018-05-22 Tue 13:57]--[2018-05-22 Tue 14:57] =>  1:00
   :END:

1. Graphical Models.
2. Fairness as independence.
3. Decision diagrams.
4. Fairness as smoothness.
5. Fairness as meritocracy.
6. Bayesian notions of fairness.


** Poject start: Fake news.

** Week 4: Clustering
   :LOGBOOK:
   CLOCK: [2018-07-17 Tue 14:21]--[2018-07-17 Tue 22:05] =>  7:44
   :END:

Unstructured databases.
Clustering / Anomaly detection.

The purpose of this lecture is to talk about non-matrix data, like
graphs, and make a link to graphical models and simple problems like
anomaly detection.


DNA testing and HMMs.

Here we talk more about unstructured data, in this case about DNA
data.

** Week 5: The web and recommendation systems

Web data, ontologies, crawling.
Knowledge representation.
 
This is web-structured data, which typically has some meta-information. 

Matrix Factorisation / LDA: Recommendation systems I (user similarity)

This lecture introduces analysis of text data, and an application to recommendation systems.

** Project start: Experiment design for energy policy or Medical Diagnostics [Aim: Reproducibility, Safety] :PROJECT:

** Lecture 1. Online data collection. Optimal stopping (expensive labels) A/B Testing, Bandit Problems.

This lecture introduces the concept of online data collection, rather than going through existing data. The applications considered are manual labelling via AMT or advertising.

** Lecture 2. Markov decision processes and Dynamic Programming (active learning and experiment design more generally)

The optimal data collection procedure can be formalised as an MDP, and this is explained here.

** Lecture 3. Safety: Risk-Sensitive Decision Making

Sometimes we are risk averse… what do we mean by this, and what algorithms can we use?

** Lecture 4. Safety: Model validation and importance Sampling

When we have developed an algorithm, how sure can we be that it works well in the real world? 
* Timetable

8.22-23 Lecture: Machine Learning intro, kNN, Reproducibility, probability and decision theory. Lab: Reproducibility
8.29-30 Lecture: Decision theory, Neural networks and SGD
9.05-06 Lab: Decision theory and Neural networks

Project 1: Mortgage decisions

9.12-13 Lecture: Privacy, anonymity, differential privacy
9.19-20 Lab: Privacy
9.26-27 Lecture: Fairness and Decision diagrams
10.03-04 Lab: Fairness, COMPAS data

Project 2: Social networks

10.10-11 Lecture: Recommendation Systems, Markov models
10.17-18 Tutorial: Bayesian Networks, Recsys
10.24-25 Lecture: Causality, Counterfactuals
10.31-11.01 Tutorial: Compression. Lab: RNN/HMM

Project 3: Experiment design

11.07-08 Lecture: Bandit Problems and MDPs
11.14-15 Tutorial: Stochastic optimisation and experiment design
11.21-22 Lecture: Reinforcement Learning, Lab: Q-learning


* Meetings
** DS overview
   CLOCK: [2018-04-23 mån 10:10]--[2018-04-23 mån 11:10] =>  1:00

Admission qualifications are quie sringent.

Maximum number of students supervised.
6 Master theses seems to be 
* MSc candidates
  :LOGBOOK:
  CLOCK: [2018-06-04 Mon 18:20]--[2018-06-04 Mon 21:52] =>  3:32
  :END:
