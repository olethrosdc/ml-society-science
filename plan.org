* Lecture plan


** Week 1: ML Intro and interpretability
   :LOGBOOK:
   CLOCK: [2018-04-04 Wed 09:22]--[2018-04-04 Wed 10:30] =>  1:08
   CLOCK: [2018-04-03 Tue 20:58]--[2018-04-03 Tue 21:16] =>  0:18
   CLOCK: [2018-04-02 Mon 21:25]--[2018-04-02 Mon 22:25] =>  1:00
   CLOCK: [2018-03-19 mån 12:04]--[2018-03-20 tis 15:57] => 27:53
   :END:
Machine learning as science: hypotheses, experiments and conclusions.
kNN example: What is classification? What is clustering? Making sure you formalise the problem.

1. KNN.
2. Reproducibility
3. Bootstrapping
4. Decision hierarchies
5. Bayesian inference
6. Optimisation and SGD.

*** Modelling :TUTORIAL:

1. Linear models
2. Neural networks
3. Confidence and $p$-values
4. Naive Bayes: Model mismatch
5. $p$-values, cross-validation and  model mismatch


The purpose of this lecture is to familiarise students with all the
decisions made from the beginning to the end of the data science
process, and with the possible externalities when an algorithm is
applied to real data.

*** Training vs test in kNN
	:LOGBOOK:
	CLOCK: [2018-05-27 Sun 14:10]--[2018-05-27 Sun 22:01] =>  7:51
	:END:

	:LOGBOOK:
        CLOCK: [2018-06-23 Sat 14:40]--[2018-06-23 Sat 15:40] =>  1:00
	CLOCK: [2018-05-28 Mon 14:49]--[2018-05-28 Mon 23:33] =>  8:44
	CLOCK: [2018-04-06 Fri 20:46]--[2018-04-06 Fri 22:15] =>  1:29
	CLOCK: [2018-04-06 Fri 15:20]--[2018-04-06 fre 16:20] =>  1:00
	:END:


Reproducibility: Finding ‘important features’ in a small dataset.  The
fallacy of p-values.  The aim of this lecture is to introduce students
to the use and mis-use of automated decision making algorithms for
problems in science and society.


** Project start: Credit risk for mortgages. [Aim: Reproducibility, Privacy and Fairness]
** Week 2: Privacy
   :LOGBOOK:
   CLOCK: [2018-07-07 Sat 15:14]
   CLOCK: [2018-07-06 Fri 15:39]--[2018-07-06 Fri 16:39] =>  1:00
   CLOCK: [2018-04-22 sön 17:16]--[2018-04-22 sön 19:19] =>  2:03
   CLOCK: [2018-04-24 tis 16:18]--[2018-04-24 tis 16:44] =>  0:26
   :END:

1. Privacy in databases.
2. k-anonymity.
3. Differential Privacy.
4. The Random Response Mechanism. 
5. Laplace Mechanism.
6. Exponential mechanism.

The purpose of this lecture is to introduce the students to basic database concepts, as well as to privacy problems that can occur when allowing access to a database to a third party.


** Week 3: Fairness
   :LOGBOOK:
   CLOCK: [2018-05-22 Tue 13:57]--[2018-05-22 Tue 14:57] =>  1:00
   :END:

1. Graphical Models.
2. Fairness as independence.
3. Decision diagrams.
4. Fairness as smoothness.
5. Fairness as meritocracy.
6. Bayesian notions of fairness.


** Poject start: Fake news.

** Week 4: Clustering

Unstructured databases.
Clustering / Anomaly detection.

The purpose of this lecture is to talk about non-matrix data, like
graphs, and make a link to graphical models and simple problems like
anomaly detection.


DNA testing and HMMs.

Here we talk more about unstructured data, in this case about DNA
data.

** Week 5: The web and recommendation systems

Web data, ontologies, crawling.
Knowledge representation.
 
This is web-structured data, which typically has some meta-information. 

Matrix Factorisation / LDA: Recommendation systems I (user similarity)

This lecture introduces analysis of text data, and an application to recommendation systems.

** Project start: Experiment design for energy policy or Medical Diagnostics [Aim: Reproducibility, Safety] :PROJECT:

** Lecture 1. Online data collection. Optimal stopping (expensive labels) A/B Testing, Bandit Problems.

This lecture introduces the concept of online data collection, rather than going through existing data. The applications considered are manual labelling via AMT or advertising.

** Lecture 2. Markov decision processes and Dynamic Programming (active learning and experiment design more generally)

The optimal data collection procedure can be formalised as an MDP, and this is explained here.

** Lecture 3. Safety: Risk-Sensitive Decision Making

Sometimes we are risk averse… what do we mean by this, and what algorithms can we use?

** Lecture 4. Safety: Model validation and importance Sampling

When we have developed an algorithm, how sure can we be that it works well in the real world? 
* Timetable

1. 22-23 August. Lecture: Machine Learning intro, kNN, Reproducibility, probability and decision theory.
2. 29-30 August. Tutorial: Reproducibility. Lab: Mortgage classification and decisions.

Project 1: Mortgage decisions

3. 5-6 September. Lecture: Privacy, anonymity, differential privacy.
4. 12-13 September. Tutorial:  Privacy. Lab: Privacy in classification.
5. 19-20 September. Lecture: Fairness and Bayesian Networks
6. 26-27 September. Tutorial: Bayesian networks. Lab: COMPAS Dataset

Project 2: Social networks

7. 3-4 October. Lecture: Clustering, DNA testing.
8. 10-11 October. Tutorial: Bayesian Networks. Lab: DNA Testing
9. 17-18 October. Lecture: Recommendation systems.
10. 24-25 October. Tutorial: Lab

Project 3: Experiment design

11. 31 Oct-1 Nov. Lecture: Bandit problems.
12. 7-8 November. Tutorial: Function optimisation. Lab: Experiment design
13. 14-15 November. Lecture: Markov decision processes.
14. 21-22 November. Tutorial: Reinforcement learning. Lab: Q-learning

* Meetings
** DS overview
   CLOCK: [2018-04-23 mån 10:10]--[2018-04-23 mån 11:10] =>  1:00

Admission qualifications are quie sringent.

Maximum number of students supervised.
6 Master theses seems to be 
* MSc candidates
  :LOGBOOK:
  CLOCK: [2018-06-04 Mon 18:20]--[2018-06-04 Mon 21:52] =>  3:32
  :END:
