* Part 1. Classification, privacy, fairness

Project: Credit risk for mortgages. [Aim: Reproducibility, Privacy and Fairness]

** Lecture 1: ML Intro

Machine learning as science: hypotheses, experiments and conclusions.
kNN example: What is classification? What is clustering? Making sure you formalise the problem.

1. KNN.
2. Reproducibility
3. Bootstrapping
4. Decision hierarchies
5. Bayesian inference
6. Optimisation and SGD.

The purpose of this lecture is to familiarise students with all the
decisions made from the beginning to the end of the data science
process, and with the possible externalities when an algorithm is
applied to real data.

*** Training vs test in kNN
	:LOGBOOK:
	CLOCK: [2018-05-27 Sun 14:10]--[2018-05-27 Sun 22:01] =>  7:51
	:END:

	:LOGBOOK:
        CLOCK: [2018-06-23 Sat 14:40]
	CLOCK: [2018-05-28 Mon 14:49]--[2018-05-28 Mon 23:33] =>  8:44
	CLOCK: [2018-04-06 Fri 20:46]--[2018-04-06 Fri 22:15] =>  1:29
	CLOCK: [2018-04-06 Fri 15:20]--[2018-04-06 fre 16:20] =>  1:00
	:END:


Reproducibility: Finding ‘important features’ in a small dataset.  The
fallacy of p-values.  The aim of this lecture is to introduce students
to the use and mis-use of automated decision making algorithms for
problems in science and society.

** Lecture 2: Model interpretability
   :LOGBOOK:
   CLOCK: [2018-04-04 Wed 09:22]--[2018-04-04 Wed 10:30] =>  1:08
   CLOCK: [2018-04-03 Tue 20:58]--[2018-04-03 Tue 21:16] =>  0:18
   CLOCK: [2018-04-02 Mon 21:25]--[2018-04-02 Mon 22:25] =>  1:00
   CLOCK: [2018-03-19 mån 12:04]--[2018-03-20 tis 15:57] => 27:53
   :END:

1. Linear models
2. Neural networks
3. Confidence and $p$-values
4. Naive Bayes: Model mismatch
5. $p$-values and model mismatch
6. Cross-validation vs Bootstrapping



*** Notes

Classification is the problem of selecting a classifier so as to make

** Lecture 3: Privacy
   CLOCK: [2018-04-24 tis 16:18]--[2018-04-24 tis 16:44] =>  0:26
   CLOCK: [2018-04-22 sön 17:16]--[2018-04-22 sön 19:19] =>  2:03

1. Privacy in databases.
2. k-anonymity.
3. Differential Privacy.
4. The Random Response Mechanism. 
5. Laplace Mechanism.
6. Exponential mechanism.

The purpose of this lecture is to introduce the students to basic database concepts, as well as to privacy problems that can occur when allowing access to a database to a third party.

** Lecture 4: Fairness
   :LOGBOOK:
   CLOCK: [2018-05-22 Tue 13:57]--[2018-05-22 Tue 14:57] =>  1:00
   :END:

1. Graphical Models.
2. Fairness as independence.
3. Decision diagrams.
4. Fairness as smoothness.
5. Fairness as meritocracy.
6. Bayesian notions of fairness.


* Part 2. Structured/unsupervised learning (social networks)

  Project: Fake news. [Aim: Reproducibility, Privacy, Fake news]

** Lecture 1: Clustering

Unstructured databases.
Clustering / Anomaly detection.

The purpose of this lecture is to talk about non-matrix data, like
graphs, and make a link to graphical models and simple problems like
anomaly detection.

** Lecture 2: DNA Testing

DNA testing and HMMs.

Here we talk more about unstructured data, in this case about DNA
data.

** Lecture 3: The web

Web data, ontologies, crawling.
Knowledge representation.
 
This is web-structured data, which typically has some meta-information. 
 
** Lecture 4: Recommendation systems

Matrix Factorisation / LDA: Recommendation systems I (user similarity)

This lecture introduces analysis of text data, and an application to recommendation systems.

* Part 3. Experiment design

Project: Experiment design for energy policy or Medical Diagnostics [Aim: Reproducibility, Safety]

** Lecture 1. Online data collection. Optimal stopping (expensive labels) A/B Testing, Bandit Problems.

This lecture introduces the concept of online data collection, rather than going through existing data. The applications considered are manual labelling via AMT or advertising.

** Lecture 2. Markov decision processes and Dynamic Programming (active learning and experiment design more generally)

The optimal data collection procedure can be formalised as an MDP, and this is explained here.

** Lecture 3. Safety: Risk-Sensitive Decision Making

Sometimes we are risk averse… what do we mean by this, and what algorithms can we use?

** Lecture 4. Safety: Model validation and importance Sampling

When we have developed an algorithm, how sure can we be that it works well in the real world? 
* Meetings
** DS overview
   CLOCK: [2018-04-23 mån 10:10]--[2018-04-23 mån 11:10] =>  1:00

Admission qualifications are quie sringent.

Maximum number of students supervised.
6 Master theses seems to be 
* MSc candidates
  :LOGBOOK:
  CLOCK: [2018-06-04 Mon 18:20]--[2018-06-04 Mon 21:52] =>  3:32
  :END:
