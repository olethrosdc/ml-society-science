@inproceedings{zhang2025hire,
  title={Hire me or not? examining language model’s behavior with occupation attributes},
  author={Zhang, Damin and Zhang, Yi and Bihani, Geetanjali and Rayz, Julia},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={7891--7911},
  year={2025}
}

@inproceedings{seshadri2025small,
  title={Small Changes, Large Consequences: Analyzing the Allocational Fairness of LLMs in Hiring Contexts},
  author={Seshadri, Preethi and Chen, Hongyu and Singh, Sameer and Goldfarb-Tarrant, Seraphina},
  booktitle={Proceedings of the 14th International Joint Conference on Natural Language Processing and the 4th Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics},
  pages={2645--2665},
  year={2025}
}


@article{an2024large,
  title={Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?},
  author={An, Haozhe and Acquaye, Christabel and Wang, Colin and Li, Zongxia and Rudinger, Rachel},
  journal={arXiv preprint arXiv:2406.10486},
  year={2024}
}
@inproceedings{veldanda2023investigating,
  title={Investigating hiring bias in large language models},
  author={Veldanda, Akshaj Kumar and Grob, Fabian and Thakur, Shailja and Pearce, Hammond and Tan, Benjamin and Karri, Ramesh and Garg, Siddharth},
  booktitle={R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models},
  year={2023}
}

@MastersThesis{monchak2025fairness,
  title={Fairness in AI-driven Recruitment: Analyzing and Mitigating Demographic Biases in Open-Source LLMs},
  author={Monchak, Tetiana},
  year={2025},
  school={Львівський державний університет внутрішніх справ}
}

@inproceedings{feldman2022hiding,
  title={Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling},
  author={Feldman, Vitaly and McMillan, Audra and Talwar, Kunal},
  booktitle={2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={954--964},
  year={2022},
  organization={IEEE}
}

@article{smith2017information,
  title={Information, privacy and stability in adaptive data analysis},
  author={Smith, Adam},
  journal={arXiv preprint arXiv:1706.00820},
  year={2017}
}

@article{balle2020privacy,
  title={Privacy profiles and amplification by subsampling},
  author={Balle, Borja and Barthe, Gilles and Gaboardi, Marco},
  journal={Journal of Privacy and Confidentiality},
  volume={10},
  number={1},
  year={2020}
}

@inproceedings{erlingsson2019amplification,
  title={Amplification by shuffling: From local to central differential privacy via anonymity},
  author={Erlingsson, {\'U}lfar and Feldman, Vitaly and Mironov, Ilya and Raghunathan, Ananth and Talwar, Kunal and Thakurta, Abhradeep},
  booktitle={Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={2468--2479},
  year={2019},
  organization={SIAM}
}

@article{sweeney2002k,
  title={k-anonymity: A model for protecting privacy},
  author={Sweeney, Latanya},
  journal={International journal of uncertainty, fuzziness and knowledge-based systems},
  volume={10},
  number={05},
  pages={557--570},
  year={2002},
  publisher={World Scientific}
}

@inproceedings{foulds:bayesian-sampling:2016,
author = {Foulds, James and Geumlek, Joseph and Welling, Max and Chaudhuri, Kamalika},
title = {On the Theory and practice of privacy-preserving Bayesian data analysis},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian inference has great promise for the privacy-preserving analysis of sensitive data, as posterior sampling automatically preserves differential privacy, an algorithmic notion of data privacy, under certain conditions (Dimitrakakis et al., 2014; Wang et al., 2015b). While this one posterior sample (OPS) approach elegantly provides privacy "for free," it is data inefficient in the sense of asymptotic relative efficiency (ARE). We show that a simple alternative based on the Laplace mechanism, the workhorse of differential privacy, is as asymptotically efficient as non-private posterior inference, under general assumptions. This technique also has practical advantages including efficient use of the privacy budget for MCMC. We demonstrate the practicality of our approach on a time-series analysis of sensitive military records from the Afghanistan and Iraq wars disclosed by the Wikileaks organization.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {192–201},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@InProceedings{pmlr-v37-wangg15,
  title = 	 {Privacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo},
  author = 	 {Wang, Yu-Xiang and Fienberg, Stephen and Smola, Alex},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2493--2502},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/wangg15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/wangg15.html},
  abstract = 	 {We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to “differential privacy”, a cryptographic approach to protect individual-level privacy while permitting database-level utility. Specifically, we show that under standard assumptions, getting one sample from a posterior distribution is differentially private “for free”; and this sample as a statistical estimator is often consistent, near optimal, and computationally tractable. Similarly but separately, we show that a recent line of work that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an “anytime” algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets.}
}

@inproceedings{nissim:ao-md:2012,
author = {Nissim, Kobbi and Smorodinsky, Rann and Tennenholtz, Moshe},
title = {Approximately optimal mechanism design via differential privacy},
year = {2012},
isbn = {9781450311151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090236.2090254},
doi = {10.1145/2090236.2090254},
abstract = {We study the implementation challenge in an abstract interdependent values model and an arbitrary objective function. We design a generic mechanism that allows for approximate optimal implementation of insensitive objective functions in ex-post Nash equilibrium. If, furthermore, values are private then the same mechanism is strategy proof. We cast our results onto two specific models: pricing and facility location. The mechanism we design is optimal up to an additive factor of the order of magnitude of one over the square root of the number of agents and involves no utility transfers.Underlying our mechanism is a lottery between two auxiliary mechanisms --- with high probability we actuate a mechanism that reduces players influence on the choice of the social alternative, while choosing the optimal outcome with high probability. This is where differential privacy is employed. With the complementary probability we actuate a mechanism that may be typically far from optimal but is incentive compatible. The joint mechanism inherits the desired properties from both.},
booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
pages = {203–213},
numpages = {11},
keywords = {differential privacy, facility location, mechanism design, monopolist pricing},
location = {Cambridge, Massachusetts},
series = {ITCS '12}
}

@inproceedings{kearns:md-privacy,
author = {Kearns, Michael and Pai, Mallesh and Roth, Aaron and Ullman, Jonathan},
title = {Mechanism design in large games: incentives and privacy},
year = {2014},
isbn = {9781450326988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554797.2554834},
doi = {10.1145/2554797.2554834},
abstract = {We study the problem of implementing equilibria of complete information games in settings of incomplete information, and address this problem using "recommender mechanisms." A recommender mechanism is one that does not have the power to enforce outcomes or to force participation, rather it only has the power to suggestion outcomes on the basis of voluntary participation. We show that despite these restrictions, recommender mechanisms can implement equilibria of complete information games in settings of incomplete information under the condition that the game is large---i.e. that there are a large number of players, and any player's action affects any other's payoff by at most a small amount.Our result follows from a novel application of differential privacy. We show that any algorithm that computes a correlated equilibrium of a complete information game while satisfying a variant of differential privacy---which we call joint differential privacy---can be used as a recommender mechanism while satisfying our desired incentive properties. Our main technical result is an algorithm for computing a correlated equilibrium of a large game while satisfying joint differential privacy.Although our recommender mechanisms are designed to satisfy game-theoretic properties, our solution ends up satisfying a strong privacy property as well. No group of players can learn "much" about the type of any player outside the group from the recommendations of the mechanism, even if these players collude in an arbitrary way. As such, our algorithm is able to implement equilibria of complete information games, without revealing information about the realized types.},
booktitle = {Proceedings of the 5th Conference on Innovations in Theoretical Computer Science},
pages = {403–410},
numpages = {8},
keywords = {differential privacy, equilibrium selection, game theory, mechanism design},
location = {Princeton, New Jersey, USA},
series = {ITCS '14}
}

  
@TechReport{Kifer2020GuidelinesFI,
  title={Guidelines for Implementing and Auditing Differentially Private Systems},
  author={D. Kifer and Solomon Messing and A. Roth and Abhradeep Thakurta and Danfeng Zhang},
  institution={ArXiv},
  year={2020},
  number={2002.04049}
}
@TechReport{Hartford:CP-DIV,
  author = 		 {Jason Hartford and Greg Lewis and Kevin Leyton-Brown and Matt Taddy},
  title = 		 {Counterfactual Prediction with Deep Instrumental Variables Networks},
  institution =  {arXiv},
  year = 		 {2016},
  number = 	 {1612.09596}
}

@inproceedings{takacs2012alternating,
  title={Alternating least squares for personalized ranking},
  author={Tak{\'a}cs, G{\'a}bor and Tikk, Domonkos},
  booktitle={Proceedings of the sixth ACM conference on Recommender systems},
  pages={83--90},
  year={2012},
  organization={ACM}
}

@article{dawid2012decision,
  title={The Decision-Theoretic Approach to Causal Inference},
  author={Dawid, Philip},
  journal={Causality: Statistical perspectives and applications},
  pages={25--42},
  year={2012},
  publisher={Wiley Online Library},
  url={https://arxiv.org/pdf/1405.2292.pdf}
}



@Book{degroot:optimalstatisticaldecisions,
  author =       "Morris H. De{G}root",
  title =        "Optimal Statistical Decisions",
  publisher =    "John Wiley \& Sons",
  year =         "1970",
}


@Book{dimitrakakis-ortner:dmuurl-book,
  author = 	 {Christos Dimitrakakis and Ronald Rotner},
  title = 	 {Decision Making Under Uncertainty and Reinforcement Learning},
  year = 		 {2019}
}

@INPROCEEDINGS {privacy-amplification-iteration,
author = { Feldman, Vitaly and Mironov, Ilya and Talwar, Kunal and Thakurta, Abhradeep },
booktitle = { 2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS) },
title = {{ Privacy Amplification by Iteration }},
year = {2018},
volume = {},
ISSN = {},
pages = {521-532},
abstract = { Many commonly used learning algorithms work by iteratively updating an intermediate solution using one or a few data points in each iteration. Analysis of differential privacy for such algorithms often involves ensuring privacy of each step and then reasoning about the cumulative privacy cost of the algorithm. This is enabled by composition theorems for differential privacy that allow releasing of all the intermediate results. In this work, we demonstrate that for contractive iterations, not releasing the intermediate results strongly amplifies the privacy guarantees. We describe several applications of this new analysis technique to solving convex optimization problems via noisy stochastic gradient descent. For example, we demonstrate that a relatively small number of non-private data points from the same distribution can be used to close the gap between private and non-private convex optimization. In addition, we demonstrate that we can achieve guarantees similar to those obtainable using the privacy-amplification-by-sampling technique in several natural settings where that technique cannot be applied. },
keywords = {Privacy;Convex functions;Machine learning algorithms;Sociology;Statistics},
doi = {10.1109/FOCS.2018.00056},
url = {https://doi.ieeecomputersociety.org/10.1109/FOCS.2018.00056},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Oct}



@InProceedings{nips:kearns:1999,
  author       = {Michael Kearns and Satinder Singh},
  title	       = {Finite sample convergence rates for Q-learning and indirect algorithms},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = 11,
  year	       = 1999,
  publisher    = {The {MIT} Press},
  pages = {996--1002}
}


@Article{mach:Watkins+Dayan:1992,
  author       = {Christopher J.C.H. Watkins and Peter Dayan},
  title	       = {Technical Note: {Q}-Learning},
  journal      = {Machine Learning},
  volume       = 8,
  year	       = 1992,
  pages	       = 279,
}


@TechReport{dimitrakakis2017:subjective-fairness,
  author={Dimitrakakis, Christos and Liu, Yang and Parkes, David and Radanovic, Goran},
  title = 		 {Bayesian Fairness},
  institution =  {arXiv},
  year = 		 {2017},
  number = 	 {1706.00119},
  url     = {https://arxiv.org/abs/1706.00119}
}

@article{werner:1965,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2283137},
 abstract = {For various reasons individuals in a sample survey may prefer not to confide to the interviewer the correct answers to certain questions. In such cases the individuals may elect not to reply at all or to reply with incorrect answers. The resulting evasive answer bias is ordinarily difficult to assess. In this paper it is argued that such bias is potentially removable through allowing the interviewee to maintain privacy through the device of randomizing his response. A randomized response method for estimating a population proportion is presented as an example. Unbiased maximum likelihood estimates are obtained and their mean square errors of conventional estimates under various assumptions about the underlying population.},
 author = {Stanley L. Warner},
 journal = {Journal of the American Statistical Association},
 number = {309},
 pages = {63--69},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias},
 urldate = {2022-08-29},
 volume = {60},
 year = {1965}
}


@article{lee2001relation,
  title={Relation between exposure to asbestos and smoking jointly and the risk of lung cancer},
  author={Lee, PN},
  journal={Occupational and environmental medicine},
  volume={58},
  number={3},
  pages={145--153},
  year={2001},
  publisher={BMJ Publishing Group Ltd}
}
@TechReport{kleinberg2016inherent,
  title={Inherent trade-offs in the fair determination of risk scores},
  author={Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  number={1609.05807},
  year={2016},
  institution={arXiv},
  keyword={"fairness", "risk scores"}
}


@Book{intro-prob:ber-tsi,
  author = 	 {Dimitri P. Bertsekas and John N. Tsitsiklis},
  title = 		 {Introduction to Probability},
  publisher = 	 {Athena Scientific},
  year = 		 {2008},
  edition = 	 {2nd}
}

@TechReport{kilbertus2017avoiding,
  title={Avoiding Discrimination through Causal Reasoning},
  author={Kilbertus, Niki and Rojas-Carulla, Mateo and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  institution={arXiv},
  number={1706.02744},
  year={2017}
}

@inproceedings{HardtPNS16,
  author = {Hardt, Moritz and Price, Eric and Srebro, Nati},
  booktitle = {NIPS},
  editor = {Lee, Daniel D. and Sugiyama, Masashi and von Luxburg, Ulrike and Guyon, Isabelle and Garnett, Roman},
  pages = {3315-3323},
  title = {Equality of Opportunity in Supervised Learning.},
  year = {2016},
}

@inproceedings{zafar2017fairness,
  title={Fairness beyond disparate treatment \& disparate impact: Learning classification without disparate mistreatment},
  author={Zafar, Muhammad Bilal and Valera, Isabel and Gomez Rodriguez, Manuel and Gummadi, Krishna P},
  booktitle={Proceedings of the 26th International Conference on World Wide Web},
  pages={1171--1180},
  year={2017},
  organization={International World Wide Web Conferences Steering Committee}
}

@article{CelisV17,
  author    = {L. Elisa Celis and
               Nisheeth K. Vishnoi},
  title     = {Fair Personalization},
  journal   = {CoRR},
  volume    = {abs/1707.02260},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.02260},
  timestamp = {Sat, 05 Aug 2017 14:56:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/CelisV17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{mach:Auer+Cesa+Fischer:2002,
  author	= {Peter Auer and Nicol\`{o} Cesa-Bianchi and Paul Fischer},
  title		= {Finite Time Analysis of the Multiarmed Bandit Problem},
  journal	= {Machine Learning},
  year		= {2002},
  volume	= {47},
  number	= {2/3},
  pages		= {235--256}
}


@article{eckles2014thompson,
  title={Thompson sampling with the online bootstrap},
  author={Eckles, Dean and Kaptein, Maurits},
  journal={arXiv preprint arXiv:1410.4009},
  year={2014}
}
@article{thompson1933lou,
  title={{On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of two Samples}},
  author={Thompson, W.R.},
  journal={Biometrika},
  volume={25},
  number={3-4},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@article{pufferfish,
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
title = {Pufferfish: A framework for mathematical privacy definitions},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0362-5915},
url = {https://doi.org/10.1145/2514689},
doi = {10.1145/2514689},
abstract = {In this article, we introduce a new and general privacy framework called Pufferfish. The Pufferfish framework can be used to create new privacy definitions that are customized to the needs of a given application. The goal of Pufferfish is to allow experts in an application domain, who frequently do not have expertise in privacy, to develop rigorous privacy definitions for their data sharing needs. In addition to this, the Pufferfish framework can also be used to study existing privacy definitions.We illustrate the benefits with several applications of this privacy framework: we use it to analyze differential privacy and formalize a connection to attackers who believe that the data records are independent; we use it to create a privacy definition called hedging privacy, which can be used to rule out attackers whose prior beliefs are inconsistent with the data; we use the framework to define and study the notion of composition in a broader context than before; we show how to apply the framework to protect unbounded continuous attributes and aggregate information; and we show how to use the framework to rigorously account for prior data releases.},
journal = {ACM Transactions on Database Systems},
month = jan,
articleno = {3},
numpages = {36},
keywords = {differential privacy, Privacy}
}

@inproceedings{blowfish,
author = {He, Xi and Machanavajjhala, Ashwin and Ding, Bolin},
title = {Blowfish privacy: tuning privacy-utility trade-offs using policies},
year = {2014},
isbn = {9781450323765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2588555.2588581},
doi = {10.1145/2588555.2588581},
abstract = {Privacy definitions provide ways for trading-off the privacy of individuals in a statistical database for the utility of downstream analysis of the data. In this paper, we present Blowfish, a class of privacy definitions inspired by the Pufferfish framework, that provides a rich interface for this trade-off. In particular, we allow data publishers to extend differential privacy using a  policy, which specifies (a) secrets, or information that must be kept secret, and (b) constraints that may be known about the data. While the secret specification allows increased utility by lessening protection for certain individual properties, the constraint specification provides added protection against an adversary who knows correlations in the data (arising from constraints). We formalize policies and present novel algorithms that can handle general specifications of sensitive information and certain count constraints. We show that there are reasonable policies under which our privacy mechanisms for k-means clustering, histograms and range queries introduce significantly lesser noise than their differentially private counterparts. We quantify the privacy-utility trade-offs for various policies analytically and empirically on real datasets.},
booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
pages = {1447–1458},
numpages = {12},
keywords = {blowfish privacy, differential privacy, privacy},
location = {Snowbird, Utah, USA},
series = {SIGMOD '14}
}

@misc{renyi-dp,
  author       = {Ilya Mironov},
  title        = {Renyi Differential Privacy},
  year         = {2017},
  note    = {arXiv: 1702.07476}
}

@misc{zc-dp,
      title={Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds}, 
      author={Mark Bun and Thomas Steinke},
      year={2016},
      eprint={1605.02065},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1605.02065}, 
}
@article{BlodgettO17,
  author    = {Su Lin Blodgett and
               Brendan O'Connor},
  title     = {Racial Disparity in Natural Language Processing: {A} Case Study of
               Social Media African-American English},
  journal   = {CoRR},
  volume    = {abs/1707.00061},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.00061},
  timestamp = {Sat, 05 Aug 2017 14:56:01 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/BlodgettO17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Chierichetti2017fair,
  title={Fair Learning in Markovian Environments},
  author={Chierichetti, Flavio and Kumar, Ravi and  Lattanzi, Silvio and Vassilvitskii, Sergei},
  journal={FATML},
  year={2017}
}

@inproceedings{kearns2017meritocratic,
  title={Meritocratic fairness for cross-population selection},
  author={Kearns, Michael and Roth, Aaron and Wu, Zhiwei Steven},
  booktitle={International Conference on Machine Learning},
  pages={1828--1836},
  year={2017}
}

@article{jabbari2016fair,
  title={Fair Learning in Markovian Environments},
  author={Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
  journal={arXiv preprint arXiv:1611.03071},
  year={2016}
}

@article{joseph2016rawlsian,
  title={Rawlsian fairness for machine learning},
  author={Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Neel, Seth and Roth, Aaron},
  journal={arXiv preprint arXiv:1610.09559},
  year={2016}
}


@article{doi:10.1080/2330443X.2017.1389620,
author = {Stephen Ansolabehere and Eitan D. Hersh},
title = {ADGN: An Algorithm for Record Linkage Using Address, Date of Birth, Gender, and Name},
journal = {Statistics and Public Policy},
volume = {4},
number = {1},
pages = {1-10},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/2330443X.2017.1389620},
URL = {https://doi.org/10.1080/2330443X.2017.1389620},
eprint = {https://doi.org/10.1080/2330443X.2017.1389620}
}

@article{breiman96bagging,
    author = "Leo Breiman",
    title = "Bagging Predictors",
    journal = "Machine Learning",
    volume = "24",
    number = "2",
    pages = "123-140",
    year = "1996",
    url = "citeseer.nj.nec.com/breiman96bagging.html" }


@inproceedings{dwork2012fairness,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
  pages={214--226},
  year={2012},
  organization={ACM}
}


@article{dwork2015reusable,
  title={The reusable holdout: Preserving validity in adaptive data analysis},
  author={Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
  journal={Science},
  volume={349},
  number={6248},
  pages={636--638},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{Bennett2009ThePC,
  title={The principled control of false positives in neuroimaging.},
  author={Craig M. Bennett and George L. Wolford and Michael B. Miller},
  journal={Social cognitive and affective neuroscience},
  year={2009},
  volume={4 4},
  pages={417-22},
  url={https://pdfs.semanticscholar.org/19c3/d8b67564d0e287a43b1e7e0f496eb1e8a945.pdf}
}

@article{bennett2012journal,
  title={Journal of Serendipitous and Unexpected Results},
  author={Bennett, Craig M and Baird, Abigail A and Miller, Michael B and Wolford, George L},
  journal={Journal of Serendipitous and Unexpected Results (jsur. org)-Vol},
  volume={1},
  number={1},
  pages={1--5},
  year={2012},
  url = {https://teenspecies.github.io/pdfs/NeuralCorrelates.pdf}
}

@inproceedings{bengio2005expected,
  title={The expected performance curve},
  author={Bengio, Samy and Mari{\'e}thoz, Johnny and Keller, Mikaela},
  booktitle={International Conference on Machine Learning, ICML, Workshop on ROC Analysis in Machine Learning},
  number={EPFL-CONF-83266},
  year={2005}
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@inproceedings{duchi2013local,
  title={Local privacy and statistical minimax rates},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J},
  booktitle={2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
  pages={429--438},
  year={2013},
  organization={IEEE}
}

@article{bayesiandp,
	author = {Dimitrakakis, Christos and Nelson, Blaine and Zhang, Zuhe and Mitrokotsa, Aikaterini and Rubinstein, Benjamin I. P.},
	title = {Differential Privacy for Bayesian Inference through Posterior Sampling},
	year = {2017},
	volume = {18},
	number = {1},
	journal = {Journal of Machine Learning Research},
	pages = {343–381},
}


@inproceedings{nissim2007smooth,
  title={Smooth sensitivity and sampling in private data analysis},
  author={Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
  booktitle={Proceedings of the thirty-ninth annual ACM symposium on Theory of computing},
  pages={75--84},
  year={2007}
}


@article{yang2020local,
	title={Local Differential Privacy and Its Applications: A Comprehensive Survey},
	author={Yang, Mengmeng and Lyu, Lingjuan and Zhao, Jun and Zhu, Tianqing and Lam, Kwok-Yan},
	journal={arXiv preprint arXiv:2008.03686},
	year={2020}
}

@inproceedings{dwork2006calibrating,
	title={Calibrating noise to sensitivity in private data analysis},
	author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	booktitle={Theory of cryptography conference},
	pages={265--284},
	year={2006},
	organization={Springer}
}

@misc{garfinkel2020randomness,
    title={Randomness Concerns When Deploying Differential Privacy},
    author={Simson L. Garfinkel and Philip Leclerc},
    year={2020},
    eprint={2009.03777},
    archivePrefix={arXiv},
    primaryClass={cs.CR}
}

@inproceedings{mcsherry2007mechanism,
  title={Mechanism design via differential privacy},
  author={McSherry, Frank and Talwar, Kunal},
  booktitle={48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)},
  pages={94--103},
  year={2007},
  organization={IEEE}
}

@TechReport{wang2017deep,
  title={Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.},
  author={Wang, Yilun and Kosinski, Michal},
  year={2017},
  instutution={PsyArXiv},
  note={\url{https://psyarxiv.com/hv28a/}}
}


@techreport{samarati1998protecting,
  title={Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression},
  author={Samarati, Pierangela and Sweeney, Latanya},
  year={1998},
  institution={technical report, SRI International}
}

@techreport{fix1951discriminatory,
  title={Discriminatory analysis-nonparametric discrimination: consistency properties},
  author={Fix, Evelyn and Hodges Jr, Joseph L},
  year={1951},
  institution={California Univ Berkeley}
}